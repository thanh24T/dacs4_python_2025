import { useState, useRef, useEffect, useCallback } from 'react';

interface Conversation {
  id: number;
  title: string;
  updated_at: string;
}

interface Message {
  role: 'user' | 'assistant';
  content: string;
  timestamp?: string;
}

function App() {
  const [isReady, setIsReady] = useState(false);
  const [userName, setUserName] = useState<string>('');
  const [userEmotion, setUserEmotion] = useState<string>('');
  const [showRegisterModal, setShowRegisterModal] = useState(false);
  const [registerName, setRegisterName] = useState<string>('');
  const [hasGreeted, setHasGreeted] = useState(false);
  
  // Chat history
  const [conversations, setConversations] = useState<Conversation[]>([]);
  const [currentConversationId, setCurrentConversationId] = useState<number | null>(null);
  const [messages, setMessages] = useState<Message[]>([]);
  const [showSidebar, setShowSidebar] = useState(true);
  
  const orbRef = useRef<HTMLDivElement>(null);
  const videoRef = useRef<HTMLVideoElement>(null); // Hidden but still used for face recognition

  // Refs quáº£n lÃ½ Audio
  const socketRef = useRef<WebSocket | null>(null);
  const audioContextRef = useRef<AudioContext | null>(null);
  const analyserRef = useRef<AnalyserNode | null>(null);
  const animationFrameRef = useRef<number>(0);

  // HÃ ng Ä‘á»£i Ã¢m thanh Ä‘á»ƒ phÃ¡t mÆ°á»£t mÃ 
  const audioQueueRef = useRef<AudioBuffer[]>([]);
  const isPlayingRef = useRef(false);

  // --- 1. VISUALIZER LOOP (Táº¡o hiá»‡u á»©ng rung) ---
  const animateOrb = useCallback(() => {
    if (!analyserRef.current || !orbRef.current) return;

    const analyser = analyserRef.current;
    const dataArray = new Uint8Array(analyser.frequencyBinCount);
    analyser.getByteFrequencyData(dataArray);

    // TÃ­nh Ä‘á»™ lá»›n Ã¢m thanh trung bÃ¬nh
    let sum = 0;
    const relevantFreqs = dataArray.slice(0, 50); // Chá»‰ láº¥y dáº£i bass/low-mid
    for (let i = 0; i < relevantFreqs.length; i++) {
      sum += relevantFreqs[i];
    }

    // Tinh chá»‰nh Ä‘á»™ nháº¡y
    let volume = (sum / relevantFreqs.length) / 100.0;
    if (volume > 1.2) volume = 1.2;
    if (volume < 0.1) volume = 0.0;


orbRef.current?.style.setProperty('--volume-level', volume.toFixed(3));
    animationFrameRef.current = requestAnimationFrame(animateOrb);
  }, []);

  // --- 2. Xá»¬ LÃ PHÃT Ã‚M THANH AI (TTS) ---
  const processAudioQueue = async () => {
    // ThÃªm dáº¥u ? vÃ o audioQueueRef.current?.length Ä‘á»ƒ trÃ¡nh lá»—i null
    if (isPlayingRef.current || (audioQueueRef.current?.length || 0) === 0 || !audioContextRef.current) return;

    isPlayingRef.current = true;

    // ThÃªm dáº¥u ? vÃ o Ä‘Ã¢y ná»¯a
    const buffer = audioQueueRef.current?.shift();

    if (buffer) {
      const source = audioContextRef.current.createBufferSource();
      source.buffer = buffer;

      if (analyserRef.current) {
        source.connect(analyserRef.current);
      }
      source.connect(audioContextRef.current.destination);

      source.onended = () => {
        isPlayingRef.current = false;
        processAudioQueue();
      };

      source.start(0);
    }
  };

  // --- 3. KHá»žI Táº O Há»† THá»NG ---
  const initializeAudio = async () => {
    try {
      console.log("ðŸš€ Äang khá»Ÿi táº¡o há»‡ thá»‘ng...");

      // A. Táº¡o AudioContext
      const AudioContext = window.AudioContext || (window as any).webkitAudioContext;
      const audioCtx = new AudioContext();
      audioContextRef.current = audioCtx;

      // B. Táº¡o Analyser (Bá»™ phÃ¢n tÃ­ch sÃ³ng Ã¢m)
      const analyser = audioCtx.createAnalyser();
      analyser.fftSize = 256;
      analyser.smoothingTimeConstant = 0.5;
      analyserRef.current = analyser;

      // C. Káº¿t ná»‘i Micro (Äá»ƒ quáº£ cáº§u rung khi Báº N nÃ³i)
      try {
        // Láº¥y video stream (khÃ´ng cÃ³ audio Ä‘á»ƒ trÃ¡nh echo)
        const videoStream = await navigator.mediaDevices.getUserMedia({ 
          audio: false,  // Táº¯t audio tá»« webcam
          video: true
        });
        
        // Láº¥y audio stream riÃªng tá»« system mic
        const audioStream = await navigator.mediaDevices.getUserMedia({
          audio: true,
          video: false
        });
        
        // Audio - Káº¿t ná»‘i system mic vá»›i analyser
        const micSource = audioCtx.createMediaStreamSource(audioStream);
        micSource.connect(analyser);
        
        // Video - Hiá»ƒn thá»‹ webcam
        if (videoRef.current) {
          videoRef.current.srcObject = videoStream;
        }
        
        // Gá»­i frame má»—i 2 giÃ¢y Ä‘á»ƒ nháº­n diá»‡n
        startFaceRecognition(videoStream);
        
      } catch (err) {
        console.warn("KhÃ´ng láº¥y Ä‘Æ°á»£c quyá»n Micro/Camera:", err);
      }

      // D. Káº¿t ná»‘i WebSocket
      connectWebSocket(audioCtx);

      // E. Báº¯t Ä‘áº§u váº½ hÃ¬nh
      animateOrb();
      setIsReady(true);

    } catch (err) {
      console.error("Lá»—i khá»Ÿi táº¡o:", err);
      alert("Lá»—i: " + err);
    }
  };

  // --- 4. FACE RECOGNITION (Hidden but still running) ---
  const startFaceRecognition = (stream: MediaStream) => {
    const canvas = document.createElement('canvas');
    const video = document.createElement('video');
    video.srcObject = stream;
    video.play();
    
    // Video is hidden, only used for face recognition
    video.style.display = 'none';
    document.body.appendChild(video);

    setInterval(() => {
      if (!socketRef.current || socketRef.current.readyState !== WebSocket.OPEN) return;

      // Capture frame
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;
      canvas.getContext('2d')?.drawImage(video, 0, 0);

      // Convert to JPEG blob
      canvas.toBlob((blob) => {
        if (blob && socketRef.current) {
          socketRef.current.send(blob);
        }
      }, 'image/jpeg', 0.8);
    }, 2000); // Má»—i 2 giÃ¢y
  };

  const connectWebSocket = (audioCtx: AudioContext) => {
      const wsUrl = 'ws://localhost:8765';
      const ws = new WebSocket(wsUrl);
      socketRef.current = ws;
      ws.binaryType = 'arraybuffer'; // Quan trá»ng Ä‘á»ƒ nháº­n file Ã¢m thanh

      ws.onopen = () => console.log("âœ… ÄÃ£ káº¿t ná»‘i tá»›i Brain!");
      ws.onclose = () => console.log("âŒ Máº¥t káº¿t ná»‘i Brain");

      ws.onmessage = async (event) => {
          // 1. Náº¿u lÃ  LOG hoáº·c TEXT (Chá»¯)
          if (typeof event.data === 'string') {
              try {
                  const data = JSON.parse(event.data);
                  if (data.type === 'log') {
                      console.log("ðŸ¤– AI:", data.content);
                  } else if (data.type === 'greeting') {
                      // Nháº­n greeting tá»« face recognition
                      console.log("ðŸ‘‹ Greeting:", data.content);
                      setAiText(data.content);
                      if (data.user) setUserName(data.user);
                      if (data.emotion) setUserEmotion(data.emotion);
                      setHasGreeted(true); // ÄÃ£ chÃ o há»i â†’ Cho phÃ©p voice chat
                  } else if (data.type === 'emotion_update') {
                      // Cáº­p nháº­t emotion liÃªn tá»¥c
                      if (data.emotion) setUserEmotion(data.emotion);
                      if (data.user) setUserName(data.user);
                  } else if (data.type === 'user_text') {
                      // Text tá»« STT
                      console.log("ðŸ‘¤ User said:", data.content);
                      setUserText(data.content);
                  } else if (data.type === 'ai_text') {
                      // Response tá»« AI
                      console.log("ðŸ¤– AI said:", data.content);
                      setAiText(data.content);
                  } else if (data.type === 'audio') {
                      console.log("ðŸ”Š Chuáº©n bá»‹ nháº­n audio...");
                  } else if (data.type === 'registration_success') {
                      // ÄÄƒng kÃ½ thÃ nh cÃ´ng
                      console.log("âœ… Registration success:", data.content);
                      alert(data.content);
                      setShowRegisterModal(false);
                      setRegisterName('');
                  } else if (data.type === 'registration_failed') {
                      // ÄÄƒng kÃ½ tháº¥t báº¡i
                      console.log("âŒ Registration failed:", data.content);
                      alert(data.content);
                  }
              } catch(e) {}
          }
          // 2. Náº¿u lÃ  AUDIO (Bytes) -> AI Ä‘ang nÃ³i
          else if (event.data instanceof ArrayBuffer) {
              console.log("ðŸ”Š Nháº­n tÃ­n hiá»‡u Ã¢m thanh...");
              try {
                  // Giáº£i mÃ£ file wav tá»« server
                  const audioBuffer = await audioCtx.decodeAudioData(event.data);
                  // Äáº©y vÃ o hÃ ng Ä‘á»£i Ä‘á»ƒ phÃ¡t
                  audioQueueRef.current.push(audioBuffer);
                  processAudioQueue();
              } catch (err) {
                  console.error("Lá»—i decode audio:", err);
              }
          }
      };
  }

  // --- 5. USER REGISTRATION ---
  const handleRegisterUser = () => {
    if (!registerName.trim()) {
      alert("Please enter your name!");
      return;
    }

    if (!socketRef.current || socketRef.current.readyState !== WebSocket.OPEN) {
      alert("WebSocket not connected!");
      return;
    }

    // Gá»­i command Ä‘Äƒng kÃ½
    socketRef.current.send(JSON.stringify({
      type: 'register_user',
      name: registerName.trim()
    }));

    console.log(`ðŸ“¸ Registering user: ${registerName}`);
  };

  // --- 6. VOICE RECORDING ---
  const startRecording = async () => {
    if (!socketRef.current || socketRef.current.readyState !== WebSocket.OPEN) {
      console.error("WebSocket chÆ°a káº¿t ná»‘i!");
      return;
    }

    try {
      // Láº¥y audio stream tá»« microphone
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      
      // Táº¡o MediaRecorder
      const mediaRecorder = new MediaRecorder(stream, {
        mimeType: 'audio/webm;codecs=opus'
      });
      
      mediaRecorderRef.current = mediaRecorder;
      audioChunksRef.current = [];

      mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          audioChunksRef.current.push(event.data);
        }
      };

      mediaRecorder.onstop = async () => {
        // Táº¡o blob tá»« chunks
        const audioBlob = new Blob(audioChunksRef.current, { type: 'audio/webm' });
        
        // Convert blob to base64
        const reader = new FileReader();
        reader.onloadend = () => {
          const base64Audio = (reader.result as string).split(',')[1];
          
          // Gá»­i lÃªn server
          if (socketRef.current && socketRef.current.readyState === WebSocket.OPEN) {
            socketRef.current.send(JSON.stringify({
              type: 'audio',
              data: base64Audio
            }));
            console.log("ðŸ“¤ ÄÃ£ gá»­i audio lÃªn server");
          }
        };
        reader.readAsDataURL(audioBlob);

        // Dá»«ng stream
        stream.getTracks().forEach(track => track.stop());
      };

      // Báº¯t Ä‘áº§u ghi
      mediaRecorder.start();
      setIsRecording(true);
      console.log("ðŸŽ¤ Báº¯t Ä‘áº§u ghi Ã¢m...");

    } catch (err) {
      console.error("Lá»—i khi ghi Ã¢m:", err);
      alert("KhÃ´ng thá»ƒ truy cáº­p microphone!");
    }
  };

  const stopRecording = () => {
    if (mediaRecorderRef.current && mediaRecorderRef.current.state === 'recording') {
      mediaRecorderRef.current.stop();
      setIsRecording(false);
      console.log("â¹ï¸ Dá»«ng ghi Ã¢m");
    }
  };

  // Cleanup khi táº¯t web
  useEffect(() => {
    return () => {
      if (socketRef.current) socketRef.current.close();
      if (audioContextRef.current) audioContextRef.current.close();
      if (animationFrameRef.current) cancelAnimationFrame(animationFrameRef.current);
    };
  }, []);

  return (
    <>
      {/* LEFT PANEL - WEBCAM */}
      <div className="left-panel">
        <div className="webcam-container">
          <video 
            ref={videoRef} 
            className="webcam-video" 
            autoPlay 
            playsInline 
            muted
          />
          {userName && (
            <div className="webcam-overlay">
              <div>ðŸ‘¤ {userName}</div>
              {userEmotion && <div>ðŸ˜Š {userEmotion}</div>}
            </div>
          )}
        </div>
        
        {/* Register Button - RA NGOÃ€I khung camera */}
        {!userName && isReady && (
          <button 
            className="register-btn-outside"
            onClick={() => setShowRegisterModal(true)}
          >
            ðŸ“¸ Register Face
          </button>
        )}
        
        {/* Voice Chat Status */}
        {isReady && (
          <div className="voice-status">
            {!hasGreeted ? (
              <div className="status-waiting">
                <div className="pulse-dot"></div>
                Waiting for greeting...
              </div>
            ) : (
              <div className="status-ready">
                <div className="ready-dot"></div>
                Voice chat ready!
              </div>
            )}
          </div>
        )}
      </div>

      {/* Registration Modal */}
      {showRegisterModal && (
        <div className="modal-overlay" onClick={() => setShowRegisterModal(false)}>
          <div className="modal-content" onClick={(e) => e.stopPropagation()}>
            <h2>Register New User</h2>
            <p>Enter your name and click Register. The system will capture your face.</p>
            <input
              type="text"
              placeholder="Your name..."
              value={registerName}
              onChange={(e) => setRegisterName(e.target.value)}
              onKeyPress={(e) => e.key === 'Enter' && handleRegisterUser()}
              autoFocus
            />
            <div className="modal-buttons">
              <button onClick={handleRegisterUser}>Register</button>
              <button onClick={() => setShowRegisterModal(false)}>Cancel</button>
            </div>
          </div>
        </div>
      )}

      {/* RIGHT PANEL - ORB */}
      <div className="right-panel">
        <div className="voice-orb-container" onClick={!isReady ? initializeAudio : undefined}>
          {/* Quáº£ cáº§u lÃµi */}
          <div ref={orbRef} className={`orb-core ${!isReady ? 'inactive' : ''}`}></div>
          {/* Váº§ng hÃ o quang */}
          <div className={`orb-glow ${!isReady ? 'inactive' : ''}`}></div>

          {!isReady && <div className="click-hint">CLICK TO START</div>}
        </div>
      </div>
    </>
  );
}

export default App;