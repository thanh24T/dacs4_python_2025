import pyaudio
import numpy as np
import torch
import time
import colorama
import collections  # Th∆∞ vi·ªán ƒë·ªÉ d√πng b·ªô ƒë·ªám v√≤ng (deque)


class VoiceDetector:
    def __init__(self):
        print(colorama.Fore.CYAN + "[VAD] Loading Silero VAD Model (Long Sentence Mode)..." + colorama.Style.RESET_ALL)
        # T·∫£i model Silero VAD
        # S·ª≠ d·ª•ng onnx=True th∆∞·ªùng nhanh v√† ·ªïn ƒë·ªãnh h∆°n tr√™n CPU
        try:
            self.model, utils = torch.hub.load(repo_or_dir='snakers4/silero-vad',
                                               model='silero_vad',
                                               trust_repo=True,
                                               onnx=True)
        except:
            # Fallback n·∫øu kh√¥ng load ƒë∆∞·ª£c onnx
            self.model, utils = torch.hub.load(repo_or_dir='snakers4/silero-vad',
                                               model='silero_vad',
                                               trust_repo=True)

        self.audio = pyaudio.PyAudio()
        self.stream = None

        # C·∫•u h√¨nh Micro
        self.FORMAT = pyaudio.paInt16
        self.CHANNELS = 1
        self.RATE = 16000
        self.CHUNK = 512  # K√≠ch th∆∞·ªõc m·ªói khung h√¨nh (frame)

        # ======================================================================
        # C·∫§U H√åNH VAD CHO C√ÇU N√ìI D√ÄI (QUAN TR·ªåNG NH·∫§T ·ªû ƒê√ÇY)
        # ======================================================================
        self.SPEECH_THRESHOLD = 0.5  # Ng∆∞·ª°ng x√°c su·∫•t (0.5 l√† m·ª©c c√¢n b·∫±ng)

        # 1. TƒÉng th·ªùi gian ch·ªù im l·∫∑ng:
        # Cho ph√©p ng·∫≠p ng·ª´ng l√™n t·ªõi 1.5 gi√¢y gi·ªØa c√¢u m√† kh√¥ng b·ªã c·∫Øt.
        self.SILENCE_DURATION = 1.5

        # 2. TƒÉng th·ªùi gian n√≥i t·ªëi ƒëa:
        # Cho ph√©p n√≥i li√™n t·ª•c l√™n t·ªõi 30 gi√¢y.
        self.MAX_SPEECH_DURATION = 30.0

        self.PRE_BUFFER_DURATION = 0.5  # Gi·ªØ nguy√™n b·ªô ƒë·ªám tr∆∞·ªõc 0.5s ƒë·ªÉ kh√¥ng m·∫•t √¢m ƒë·∫ßu
        # ======================================================================

        # T√≠nh to√°n s·ªë l∆∞·ª£ng frame cho b·ªô ƒë·ªám tr∆∞·ªõc
        self.pre_buffer_frames = int((self.RATE * self.PRE_BUFFER_DURATION) / self.CHUNK)

        # Index c·ªßa Microphone ∆∞u ti√™n (Thay ƒë·ªïi n·∫øu c·∫ßn)
        self.PREFERRED_MIC_INDEX = 1
        self.is_muted = False  # Th√™m flag ƒë·ªÉ ki·ªÉm so√°t mute/unmute
        self._init_stream()

    def _init_stream(self):
        if self.stream:
            try:
                self.stream.close()
            except:
                pass
        try:
            # Th·ª≠ m·ªü mic ID ∆∞u ti√™n
            self.stream = self.audio.open(format=self.FORMAT,
                                          channels=self.CHANNELS,
                                          rate=self.RATE,
                                          input=True,
                                          input_device_index=self.PREFERRED_MIC_INDEX,
                                          frames_per_buffer=self.CHUNK)
            print(
                colorama.Fore.GREEN + f"[VAD] ‚úÖ ƒê√£ k·∫øt n·ªëi Micro ID {self.PREFERRED_MIC_INDEX}" + colorama.Style.RESET_ALL)
            return True
        except:
            # Fallback mic m·∫∑c ƒë·ªãnh
            print(
                colorama.Fore.YELLOW + f"[VAD] Kh√¥ng m·ªü ƒë∆∞·ª£c Mic ID {self.PREFERRED_MIC_INDEX}, chuy·ªÉn sang mic m·∫∑c ƒë·ªãnh h·ªá th·ªëng." + colorama.Style.RESET_ALL)
            try:
                self.stream = self.audio.open(format=self.FORMAT,
                                              channels=self.CHANNELS,
                                              rate=self.RATE,
                                              input=True,
                                              frames_per_buffer=self.CHUNK)
                print(colorama.Fore.GREEN + "[VAD] ‚úÖ ƒê√£ k·∫øt n·ªëi Micro m·∫∑c ƒë·ªãnh." + colorama.Style.RESET_ALL)
                return True
            except Exception as e:
                print(
                    colorama.Fore.RED + f"[VAD L·ªói Init] Kh√¥ng th·ªÉ m·ªü b·∫•t k·ª≥ Micro n√†o: {e}" + colorama.Style.RESET_ALL)
                return False

    def mute(self):
        """T·∫Øt mic (d·ª´ng stream t·∫°m th·ªùi)"""
        self.is_muted = True
        if self.stream and self.stream.is_active():
            self.stream.stop_stream()
            print(colorama.Fore.YELLOW + "[VAD] üîá Mic MUTED" + colorama.Style.RESET_ALL)
    
    def unmute(self):
        """M·ªü l·∫°i mic"""
        self.is_muted = False
        if self.stream and not self.stream.is_active():
            self.stream.start_stream()
            print(colorama.Fore.GREEN + "[VAD] üîä Mic UNMUTED" + colorama.Style.RESET_ALL)

    def listen(self):
        # N·∫øu mic ƒëang b·ªã mute, kh√¥ng nghe
        if self.is_muted:
            time.sleep(0.1)
            return None
        
        # frames: Danh s√°ch ch·ª©a d·ªØ li·ªáu √¢m thanh ch√≠nh th·ª©c c·ªßa c√¢u n√≥i
        frames = []
        # pre_buffer: B·ªô ƒë·ªám v√≤ng ƒë·ªÉ l∆∞u √¢m thanh tr∆∞·ªõc khi n√≥i (tr√°nh m·∫•t √¢m ƒë·∫ßu)
        pre_buffer = collections.deque(maxlen=self.pre_buffer_frames)

        silence_start_time = None
        speech_start_time = None
        is_speaking = False

        # Ki·ªÉm tra v√† kh·ªüi t·∫°o l·∫°i stream n·∫øu c·∫ßn
        if self.stream is None or not self.stream.is_active():
            if not self._init_stream():
                time.sleep(2)  # Ch·ªù l√¢u h∆°n x√≠u tr∆∞·ªõc khi th·ª≠ l·∫°i
                return None

        while True:
            try:
                # ƒê·ªçc d·ªØ li·ªáu t·ª´ micro
                data = self.stream.read(self.CHUNK, exception_on_overflow=False)

                # Chu·∫©n b·ªã d·ªØ li·ªáu cho model VAD (float32)
                audio_chunk = np.frombuffer(data, dtype=np.int16).astype(np.float32) / 32768.0

                # D·ª± ƒëo√°n x√°c su·∫•t gi·ªçng n√≥i
                with torch.no_grad():
                    # S·ª≠ d·ª•ng model(tensor, rate) l√† c√°ch g·ªçi chu·∫©n cho Silero
                    prob = self.model(torch.from_numpy(audio_chunk), self.RATE).item()

                if prob > self.SPEECH_THRESHOLD:
                    # --- PH√ÅT HI·ªÜN ƒêANG N√ìI ---
                    if not is_speaking:
                        # B·∫Øt ƒë·∫ßu m·ªôt c√¢u n√≥i m·ªõi
                        is_speaking = True
                        speech_start_time = time.time()
                        # print(colorama.Fore.CYAN + "\n[VAD] >> B·∫Øt ƒë·∫ßu n√≥i..." + colorama.Style.RESET_ALL)

                        # Th√™m b·ªô ƒë·ªám tr∆∞·ªõc v√†o ƒë·∫ßu danh s√°ch frames
                        frames.extend(pre_buffer)
                        pre_buffer.clear()

                    # Reset th·ªùi gian t√≠nh im l·∫∑ng v√¨ ƒëang n√≥i
                    silence_start_time = None
                    # L∆∞u frame hi·ªán t·∫°i
                    frames.append(data)

                else:
                    # --- PH√ÅT HI·ªÜN IM L·∫∂NG (HO·∫∂C TI·∫æNG ·ªíN NH·ªé) ---
                    if is_speaking:
                        # ƒêang trong tr·∫°ng th√°i n√≥i m√† g·∫∑p im l·∫∑ng
                        frames.append(data)  # V·∫´n l∆∞u kho·∫£ng l·∫∑ng n√†y v√†o c√¢u

                        if silence_start_time is None:
                            silence_start_time = time.time()

                        # ƒêI·ªÄU KI·ªÜN 1: Ng·∫Øt c√¢u n·∫øu im l·∫∑ng ƒë·ªß l√¢u (SILENCE_DURATION)
                        if time.time() - silence_start_time > self.SILENCE_DURATION:
                            # print(colorama.Fore.GREEN + f"[VAD] >> ƒê√£ ng·∫Øt c√¢u (Im l·∫∑ng > {self.SILENCE_DURATION}s)" + colorama.Style.RESET_ALL)
                            return b''.join(frames)
                    else:
                        # Ch∆∞a n√≥i g√¨, ch·ªâ l√† ti·∫øng ·ªìn n·ªÅn -> L∆∞u v√†o b·ªô ƒë·ªám tr∆∞·ªõc
                        pre_buffer.append(data)

                # ƒêI·ªÄU KI·ªÜN 2: Ng·∫Øt c∆∞·ª°ng √©p n·∫øu n√≥i qu√° d√†i (MAX_SPEECH_DURATION)
                if is_speaking and speech_start_time and (time.time() - speech_start_time > self.MAX_SPEECH_DURATION):
                    print(
                        colorama.Fore.YELLOW + f"\n[VAD] >> ƒê√£ ng·∫Øt c√¢u (Qu√° d√†i > {self.MAX_SPEECH_DURATION}s)" + colorama.Style.RESET_ALL)
                    return b''.join(frames)

            except IOError as e:
                # L·ªói th∆∞·ªùng g·∫∑p khi mic b·ªã r√∫t ra ho·∫∑c qu√° t·∫£i
                print(
                    colorama.Fore.YELLOW + f"\n[VAD Warning] L·ªói ƒë·ªçc Mic (IOError), ƒëang th·ª≠ l·∫°i..." + colorama.Style.RESET_ALL)
                self._init_stream()
                time.sleep(0.5)
                # Reset tr·∫°ng th√°i ƒë·ªÉ tr√°nh l·ªói logic
                frames = []
                pre_buffer.clear()
                is_speaking = False
            except Exception as e:
                print(colorama.Fore.RED + f"\n[VAD Critical Error] {e}" + colorama.Style.RESET_ALL)
                self._init_stream()
                time.sleep(1)
                return None